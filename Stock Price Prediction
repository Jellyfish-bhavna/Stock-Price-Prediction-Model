# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from xgboost import XGBClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report

# Load the dataset
url = 'path_to_tesla_stock_dataset.csv'
df = pd.read_csv(url)

# Preprocess the dataset
# Assuming 'Date' is the date column and 'Close' is the target column
df['Date'] = pd.to_datetime(df['Date'])
df.set_index('Date', inplace=True)

# Creating features and labels
df['Price_Up'] = (df['Close'].shift(-1) > df['Close']).astype(int)
df.dropna(inplace=True)

# Selecting features
X = df[['Open', 'High', 'Low', 'Close', 'Volume']]
y = df['Price_Up']

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Define the models and their parameters for GridSearchCV
models = {
    'Logistic Regression': {
        'model': LogisticRegression(),
        'params': {
            'C': [0.01, 0.1, 1, 10, 100],
            'solver': ['lbfgs', 'liblinear']
        }
    },
    'Decision Tree': {
        'model': DecisionTreeClassifier(),
        'params': {
            'max_depth': [3, 5, 7, 10],
            'min_samples_split': [2, 5, 10]
        }
    },
    'XGBoost': {
        'model': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss'),
        'params': {
            'n_estimators': [50, 100, 200],
            'learning_rate': [0.01, 0.1, 0.2],
            'max_depth': [3, 5, 7]
        }
    },
    'KNN': {
        'model': KNeighborsClassifier(),
        'params': {
            'n_neighbors': [3, 5, 7, 9],
            'weights': ['uniform', 'distance']
        }
    }
}

# Apply GridSearchCV and find the best model
best_models = {}
for model_name, mp in models.items():
    clf = GridSearchCV(mp['model'], mp['params'], cv=5, scoring='accuracy')
    clf.fit(X_train, y_train)
    best_models[model_name] = clf.best_estimator_
    print(f'Best parameters for {model_name}: {clf.best_params_}')
    print(f'Best score for {model_name}: {clf.best_score_}')

# Evaluate the best models on the test set
for model_name, model in best_models.items():
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    print(f'Accuracy of {model_name}: {accuracy}')
    print(classification_report(y_test, y_pred))
